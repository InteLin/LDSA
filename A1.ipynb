{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 (word count example)\n",
    "Created an instance based on the “​ Hadoop-Lab2-volume-final-snapshot​ ” snapshot. Connected using commands ```chmod 700 ldsa.pem``` and ```ssh -i ldsa.pem ubuntu@129.16.122.22```. \n",
    "Added hostname 'haol-a1' to etc/hosts.\n",
    "Downloaded input data using command ```wget http://www.gutenberg.org/ebooks/20417.txt.utf-8```\n",
    "Executed command ```/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop*examples*.jar wordcount input output```\n",
    "#### Questions:\n",
    " - Look at the contents of the folder “output” - what are the files place in there? What do they mean?\n",
    " \n",
    "There are two files called _SUCCESS and part-r-00000. _SUCCESS is empty but the fact that it has been created menas the operation was completed successfully. part-r-00000 contains the result of the reudction; all the words and how many of them appear.\n",
    " \n",
    "  - In this example we used Hadoop in “​ Local (Standalone) Mode​ ”. What is the difference between this mode and the Pseudo-distributed mode?\n",
    "  \n",
    "The difference between Local (Standalone) mode and Pseudo-distributed mode is that in standalone mode hadoop runs as a single Java process without any daemons. In this case HDFS is not used.\n",
    "Pseudo-distributed mode means that a small scale cluster is simulated, running daemons on the local machine and using HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2\n",
    "Setup hadoop as pseudo-distributed by going to '/usr/local/hadoop/etc/hadoop/core-site.xml' and adding:\n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://localhost:9000</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "and to '/usr/local/hadoop/etc/hadoop/hdfs-site.xml': \n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>1</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "These three commands were executed in order to get passphraseless connection to localhost ssh:\n",
    "\n",
    "  ```$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa ```\n",
    "  \n",
    "  ```$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys```\n",
    "  \n",
    "  ```$ chmod 0600 ~/.ssh/authorized_keys```\n",
    "  \n",
    "System was formatted using command \n",
    "```$ bin/hdfs namenode -format```\n",
    "NameNode and DataNode daemons were started by executing command \n",
    "```$ sbin/start-dfs.sh```\n",
    "\n",
    "```$ jps``` gave out:\n",
    "\n",
    "16912 SecondaryNameNode\n",
    "\n",
    "17026 Jps\n",
    "\n",
    "16642 NameNode\n",
    "\n",
    "16756 DataNode\n",
    "\n",
    "so everything seemed to be in order.\n",
    "\n",
    "#### Questions: \n",
    " - What are the roles of the files core-site.xml and hdfs-site.xml ?\n",
    "The role of core-site.xml is for any site-specific property overrides that the user might want to define. In our example we defined where in the cluster namenode should run.\n",
    "Hdfs-site.xml contains the configuration settings for the hdfs daemons (NameNode, Secondary NameNode and the DataNodes). \n",
    "\n",
    " - Describe briefly the roles of the different services listed when executing ‘jps’.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3\n",
    "Compiled the wordcount example and made a jar-file by executing commands:\n",
    "\n",
    "```$ cd /home/ubuntu/wordcount```\n",
    "\n",
    "```$ javac –cp `/usr/local/hadoop/bin/hadoop classpath` WordCount.java```\n",
    "\n",
    "```$ jar -cvf wordcount.jar *.cla```\n",
    "\n",
    "Ran the hadoop code using command:\n",
    "\n",
    "```$ /usr/local/hadoop/bin/hadoop jar wordcount.jar WordCount input output2```\n",
    "\n",
    "Ran command:\n",
    "\n",
    "```$ /usr/local/hadoop/bin/hdfs dfs -ls output2```\n",
    "\n",
    "It showed the two files '_SUCCESS' and 'part-00000'\n",
    "\n",
    "The command:\n",
    "\n",
    "```$ /usr/local/hadoop/bin/hdfs dfs -ls output2/part-00000```\n",
    "\n",
    "showed the contents of the result files, all semmes to have worked fine.\n",
    "\n",
    "#### Questions:\n",
    " - Explain the roles of the different classes in the file WordCount.java.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
